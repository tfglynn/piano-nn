{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tfglynn/piano-nn/blob/master/October_piano_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lilypond"
      ],
      "metadata": {
        "id": "pThSg2aGwDj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install lilypond"
      ],
      "metadata": {
        "id": "bMM1Bie3wFef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Server"
      ],
      "metadata": {
        "id": "Xm4cNvCf2DHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copied from elsewhere\n",
        "\n",
        "import os, sys, requests, json\n",
        "from multiprocessing import Process\n",
        "from flask import Flask, request, abort, logging\n",
        "\n",
        "run_thread = True\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/\", methods=['GET'])\n",
        "def test():\n",
        "    salida = {'status':'OK','message':'Test'}\n",
        "    return json.dumps(salida)\n",
        "\n",
        "@app.route(\"/echo\", methods=[\"GET\"])\n",
        "def echo():\n",
        "    if (msg := request.headers.get(\"message\")) is not None:\n",
        "        return json.dumps({\"echo\": msg})\n",
        "\n",
        "def stop_server():\n",
        "  global server\n",
        "  if server is not None:\n",
        "    server.terminate()\n",
        "    server.join()\n",
        "\n",
        "def start_server(run_thread):\n",
        "  global server\n",
        "  if run_thread:\n",
        "    server = Process(target=app.run, kwargs={\"host\": \"localhost\", \"port\": 8000})\n",
        "    server.start()\n",
        "  else:\n",
        "    app.run(host=\"localhost\", port=8000)"
      ],
      "metadata": {
        "id": "hxUN63xlKHfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_server()"
      ],
      "metadata": {
        "id": "FjT7nhrNOcA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_server(run_thread)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aTdwSD7KWPz",
        "outputId": "c9b78b47-8118-42bf-e88d-b2a68f935c8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://localhost:8000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install -g localtunnel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTOjn8eeNfXI",
        "outputId": "3f271706-2032-4397-e452-31c58ee131db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h/tools/node/bin/lt -> /tools/node/lib/node_modules/localtunnel/bin/lt.js\n",
            "+ localtunnel@2.0.2\n",
            "added 22 packages from 22 contributors in 2.282s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-7o1rizN81I",
        "outputId": "510ef34f-d8fc-4072-b390-b6417377c12c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "104.199.147.125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup lt --port 8000 >lt.log 2>&1 &"
      ],
      "metadata": {
        "id": "d_3uhnfkNhcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat lt.log"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImiwOVcdQ8WN",
        "outputId": "1dab2113-2a9b-4e76-b9dc-d523f6e187f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "your url is: https://shy-plums-poke.loca.lt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ps -ef | grep lt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGbplIIWQsOX",
        "outputId": "cfc0861c-4a82-44cc-a9cc-8f7ca13feade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root          83       7  0 01:15 ?        00:00:01 /usr/local/bin/dap_multiplexer --domain_socket_path=/tmp/debugger_26lqol2dmg\n",
            "root       13389       1  0 02:10 ?        00:00:00 node /tools/node/bin/lt --port 8000\n",
            "root       15505    5834  0 02:18 ?        00:00:00 /bin/bash -c ps -ef | grep lt\n",
            "root       15507   15505  0 02:18 ?        00:00:00 grep lt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kill 13389"
      ],
      "metadata": {
        "id": "tPNxTX6hS5Cg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e75erekQP8v"
      },
      "source": [
        "# Preamble"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0tBEQM8QStg"
      },
      "source": [
        "## Installing libraries we need"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6wD1HE-QVdD"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install pretty_midi\n",
        "!pip install rotary-embedding-torch\n",
        "#!pip install hdbscan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hF-aV0YtQUSK"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etfX0tXr0o3h"
      },
      "outputs": [],
      "source": [
        "import bisect\n",
        "import copy\n",
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pathlib\n",
        "import pickle\n",
        "import PIL\n",
        "import pretty_midi as pm\n",
        "import subprocess\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import warnings\n",
        "from collections import Counter\n",
        "from enum import Enum\n",
        "from functools import partial\n",
        "from google.colab import drive\n",
        "#from hdbscan import HDBSCAN\n",
        "from IPython.display import display, HTML, Image\n",
        "from matplotlib import collections as mc\n",
        "from operator import attrgetter, itemgetter\n",
        "from sklearn.manifold import TSNE\n",
        "from torch import optim\n",
        "from torch.distributions import Beta\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from rotary_embedding_torch import RotaryEmbedding"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Globals"
      ],
      "metadata": {
        "id": "Q86FPO1rw9C0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DEFAULT_EPSILON = 1e-6\n",
        "INCLUDE_SONG_BOUNDARIES = False\n",
        "N_KEYS = 88 # all keys of a piano\n",
        "NEXT_TOKEN = 0\n",
        "BOUNDARY_TOKEN = N_KEYS + 1\n",
        "\n",
        "MIN_PITCH = 21 # lowest A\n",
        "MAX_PITCH = MIN_PITCH + N_KEYS - 1 # highest C\n",
        "\n",
        "# Lilypond names\n",
        "SHIFT_NAMES = [\"32\", \"16\", \"16.\", \"8\", \"8.\", \"4\", \"4.\", \"2\", \"2.\", \"1\", \"1.\", \"breve\"]\n",
        "PITCH_NAMES = [\"a\", \"ais\", \"b\", \"c\", \"cis\", \"d\", \"dis\", \"e\", \"f\", \"fis\", \"g\", \"gis\"]\n",
        "\n",
        "BATCH_SIZE = 4\n",
        "CONTEXT_WINDOW = 1024\n",
        "N_TRAINING_STEPS = 100_000\n",
        "LEARNING_RATE = 1e-3\n",
        "\n",
        "N_EVENTS = N_KEYS + (2 if INCLUDE_SONG_BOUNDARIES else 1)\n",
        "N_SHIFTS = 12 # 32, 16, 16., 8, 8., 4, 4., 2, 2., 1, 1., breve"
      ],
      "metadata": {
        "id": "m3ShFK82w-T_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBvYRUf6R5wc"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device_name = \"cuda\"\n",
        "    print(\"GPU support enabled\")\n",
        "else:\n",
        "    device_name = \"cpu\"\n",
        "    print(\"Using CPU only\")\n",
        "device = torch.device(device_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRFxjsMC79yx",
        "outputId": "fbb1810c-67ae-41bf-83fe-4815537d3cfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU support enabled\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZvJFP2F8FJp",
        "outputId": "4044d765-0846-46b8-e017-1e93b2b672b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utilities"
      ],
      "metadata": {
        "id": "cwjvDZSbx4Mc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pitch_name(p):\n",
        "    p = p - MIN_PITCH + 1\n",
        "    return PITCH_NAMES[(p - 1) % 12]"
      ],
      "metadata": {
        "id": "B5ce0ESGxOF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ma(x, w):\n",
        "    return np.convolve(x, np.ones(w), \"valid\") / w"
      ],
      "metadata": {
        "id": "dR5QXUYRxZ8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rolling(x, r):\n",
        "    \"\"\"Repeats `x` and rolls it `r` times\n",
        "\n",
        "    x: (B?, T, D)\n",
        "    r: a positive integer\n",
        "\n",
        "    Returns: (B?, r, T, D)\n",
        "    \"\"\"\n",
        "    t = x.shape[-2]\n",
        "    reps = (1, r, 1, 1) if x.dim() == 3 else (r, 1, 1)\n",
        "    x = x.unsqueeze(-3).repeat(reps)\n",
        "    x = F.pad(x, (0, 0, 0, 1)).flatten(-3, -2)[..., :r*t, :].view(x.shape)\n",
        "    return x"
      ],
      "metadata": {
        "id": "VjHOu-2KApnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def l2_normalize(x, eps=1e-5):\n",
        "    \"\"\"Turns a tensor of shape (..., D) into unit vectors\"\"\"\n",
        "    return x * torch.rsqrt(eps + x.pow(2).sum(dim=-1, keepdim=True))"
      ],
      "metadata": {
        "id": "KtsMVF0FBnLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if INCLUDE_SONG_BOUNDARIES:\n",
        "    def chord_indices(x):\n",
        "        punctuation = ((x == 0) | (x == N_EVENTS - 1)).int().to(device)\n",
        "        return punctuation.cumsum(dim=-1) - punctuation + 1\n",
        "else:\n",
        "    def chord_indices(x):\n",
        "        punctuation = (x == 0).int().to(device)\n",
        "        return punctuation.cumsum(dim=-1) - punctuation + 1"
      ],
      "metadata": {
        "id": "BEnV-w3PNIEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chord_position(x):\n",
        "    punctuation = (x == 0).long().to(device)\n",
        "    n = torch.arange(x.shape[-1], dtype=torch.long).to(device)\n",
        "    if x.dim() == 2:\n",
        "        n = n.unsqueeze(0)\n",
        "    return n - F.pad(((n + 1) * punctuation)[..., :-1].cummax(dim=-1)[0], (1, 0))"
      ],
      "metadata": {
        "id": "Tsg0vLR2mJaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Progress bar"
      ],
      "metadata": {
        "id": "nzg9UYWcx2i5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Progress:\n",
        "    def __init__(self, it, max=None):\n",
        "        if max is None:\n",
        "            max = len(it)\n",
        "        self.max = max\n",
        "        self.bar = display(self.html(0, max), display_id=True)\n",
        "        self.i = 0\n",
        "        self.it = iter(it)\n",
        "\n",
        "    def html(self, value, max):\n",
        "        return HTML(\"\"\"\n",
        "            <progress value=\"{value}\" max=\"{max}\", style=\"width: 90%; background-color: black\">\n",
        "            {value}\n",
        "            </progress>\n",
        "        \"\"\".format(value=value, max=max))\n",
        "\n",
        "    def __iter__(self):\n",
        "        try:\n",
        "            while True:\n",
        "                x = next(self.it)\n",
        "                self.i += 1\n",
        "                self.bar.update(self.html(self.i % self.max, self.max))\n",
        "                yield x\n",
        "        except StopIteration:\n",
        "            pass\n",
        "\n",
        "def progress(it, max=None):\n",
        "    return Progress(it, max)"
      ],
      "metadata": {
        "id": "VMD2mMCcJPRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MIDI conversion"
      ],
      "metadata": {
        "id": "E7u_fPJix0A3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dedup(events, shifts):\n",
        "    deduped_events = []\n",
        "    deduped_shifts = []\n",
        "    e1 = events[0]\n",
        "    s1 = shifts[0]\n",
        "    for e2, s2 in zip(events[1:], shifts[1:]):\n",
        "        if e2 == e1:\n",
        "            s1 = max(s1, s2)\n",
        "        else:\n",
        "            deduped_events.append(e1)\n",
        "            deduped_shifts.append(s1)\n",
        "            e1, s1 = e2, s2\n",
        "    deduped_events.append(e1)\n",
        "    deduped_shifts.append(s1)\n",
        "    return (deduped_events, deduped_shifts)"
      ],
      "metadata": {
        "id": "b7WZP4Lmxfoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def midi_to_instructions(mid, eps_scale=(2 ** 3)):\n",
        "    mid = copy.deepcopy(mid)\n",
        "    tempo = mid.estimate_tempo()\n",
        "    qnote = 60 / tempo\n",
        "    notes = sum([i.notes for i in mid.instruments if not i.is_drum], start=[])\n",
        "    notes = sorted(notes, key=lambda n: n.start)\n",
        "\n",
        "    #\n",
        "    # Step 1: Cleanup\n",
        "    #\n",
        "\n",
        "    # The estimated tempo is probably slightly off, so we'll try to find\n",
        "    # a representative note.\n",
        "    for n in notes:\n",
        "        if np.abs((duration := n.end - n.start) - qnote) < qnote / eps_scale:\n",
        "            qnote = duration\n",
        "            break\n",
        "    eps = qnote / eps_scale\n",
        "\n",
        "    # If 1/10 of the notes are about to get thrown out, shrink the quarter note.\n",
        "    if np.mean([n.end - n.start < 1.5 * eps for n in notes]) >= 0.1:\n",
        "        qnote /= 2\n",
        "        eps /= 2\n",
        "\n",
        "    # Throw out any garbage\n",
        "    notes = [n for n in notes if n.end - n.start >= 1.5 * eps]\n",
        "\n",
        "    #\n",
        "    # Step 2: Adjusting everything\n",
        "    #\n",
        "\n",
        "    moments = []\n",
        "    for i, n in enumerate(notes):\n",
        "        moments.append((n.start, \"s\", i))\n",
        "        moments.append((n.end, \"e\", i))\n",
        "    moments = sorted(moments, key=lambda m: m[0])\n",
        "    clusters = []\n",
        "    current_cluster = [moments[0]]\n",
        "    for moment in moments[1:]:\n",
        "        if (\n",
        "            moment[0] < np.mean([m[0] for m in current_cluster]) + eps and\n",
        "            moment[-1] not in [m[-1] for m in current_cluster]):\n",
        "            current_cluster.append(moment)\n",
        "            # Is the cluster too big?\n",
        "            if current_cluster[-1][0] - current_cluster[0][0] > eps:\n",
        "                c1, c2 = [current_cluster[0]], [current_cluster[-1]]\n",
        "                for c in current_cluster[1:-1]:\n",
        "                    d1 = c[0] - current_cluster[0][0]\n",
        "                    d2 = current_cluster[-1][0] - c[0]\n",
        "                    if d1 > d2:\n",
        "                        c2.append(c)\n",
        "                    else:\n",
        "                        c1.append(c)\n",
        "                clusters.append(c1)\n",
        "                current_cluster = c2\n",
        "        else:\n",
        "            clusters.append(current_cluster)\n",
        "            current_cluster = [moment]\n",
        "    clusters.append(current_cluster)\n",
        "\n",
        "    for cluster in clusters:\n",
        "        avg = np.mean([m[0] for m in cluster])\n",
        "        for _, kind, i in cluster:\n",
        "            if kind == \"s\":\n",
        "                notes[i].start = avg\n",
        "            else: # e\n",
        "                notes[i].end = avg\n",
        "\n",
        "    mid.instruments = [pm.Instrument(program=0)]\n",
        "    mid.instruments[0].notes = notes\n",
        "\n",
        "    # This is the last chance to get a different quarter note\n",
        "    tempo = mid.estimate_tempo()\n",
        "    qnote = 60 / tempo\n",
        "    for n in notes:\n",
        "        if np.abs((duration := n.end - n.start) - qnote) < qnote / eps_scale:\n",
        "            qnote = duration\n",
        "            break\n",
        "    eps = qnote / eps_scale\n",
        "\n",
        "    #\n",
        "    # Step 2: Actually discretize it\n",
        "    #\n",
        "\n",
        "    notes = sorted(notes, key=lambda n: (n.start, -n.pitch)) # negative pitch so it's high to low\n",
        "    events = []\n",
        "    shifts = []\n",
        "    clock = notes[0].start\n",
        "    for n in notes:\n",
        "        if n.end - n.start < eps:\n",
        "            continue\n",
        "        if (start := n.start) > clock:\n",
        "            events.append(NEXT_TOKEN)\n",
        "            shifts.append(start - clock)\n",
        "            clock = start\n",
        "        events.append(np.clip(n.pitch, MIN_PITCH, MAX_PITCH) - MIN_PITCH + 1)\n",
        "        shifts.append(n.end - start)\n",
        "    end = max(n.end for n in notes)\n",
        "    events.append(NEXT_TOKEN)\n",
        "    shifts.append(end - clock)\n",
        "\n",
        "    # Make sure no notes got doubled up.\n",
        "    events, shifts = dedup(events, shifts)\n",
        "\n",
        "    events = np.array(events)\n",
        "    shifts = np.array(shifts)\n",
        "    # We need to make sure all the standard shifts are in order,\n",
        "    # for the relative encoding to work.\n",
        "    powers = np.power(2., np.array([-2, -1, 0, 1, 2]))\n",
        "    standard_shifts = np.empty(2 + 2 * powers.size, dtype=np.float32)\n",
        "    standard_shifts[0] = 2 ** -3\n",
        "    standard_shifts[-1] = 2 ** 3\n",
        "    standard_shifts[1:-1:2] = powers\n",
        "    standard_shifts[2:-1:2] = 1.5 * powers\n",
        "    standard_shifts *= qnote\n",
        "    shifts = np.argmin(\n",
        "        np.abs(shifts.reshape(-1, 1) - standard_shifts.reshape(1, -1)),\n",
        "        axis=-1)\n",
        "\n",
        "    events = np.concatenate([[BOUNDARY_TOKEN], events, [BOUNDARY_TOKEN]])\n",
        "    shifts = np.concatenate([[0], shifts, [0]])\n",
        "\n",
        "    return (events, shifts, tempo)"
      ],
      "metadata": {
        "id": "G6CxiaRQxkx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "powers = np.power(2., np.array([-2, -1, 0, 1, 2]))\n",
        "SHIFT_LENGTHS = np.empty(2 + 2 * powers.size, dtype=np.float32)\n",
        "SHIFT_LENGTHS[0] = 2 ** -3\n",
        "SHIFT_LENGTHS[-1] = 2 ** 3\n",
        "SHIFT_LENGTHS[1:-1:2] = powers\n",
        "SHIFT_LENGTHS[2:-1:2] = 1.5 * powers\n",
        "\n",
        "SHIFT_LENGTHS_TENSOR = torch.tensor(SHIFT_LENGTHS).to(device)\n",
        "\n",
        "def instructions_to_midi(events, shifts, tempo=120):\n",
        "    qnote = 60 / tempo\n",
        "    standard_shifts = SHIFT_LENGTHS * qnote\n",
        "\n",
        "    mid = pm.PrettyMIDI()\n",
        "    mid.instruments.append(pm.Instrument(0)) # piano\n",
        "    notes = []\n",
        "    clock = 0\n",
        "    for e, s in zip(events, shifts):\n",
        "        if e == BOUNDARY_TOKEN:\n",
        "            continue\n",
        "        if e == NEXT_TOKEN:\n",
        "            clock += standard_shifts[s]\n",
        "        else:\n",
        "            end = clock + standard_shifts[s]\n",
        "            notes.append(pm.Note(127, int(e) - 1 + MIN_PITCH, clock, end))\n",
        "    mid.instruments[0].notes = notes\n",
        "    return mid\n",
        "\n",
        "def plot_midi(mid, title=None, filename=None, extrapolated=0, crop=None, truncate=0, beginning_marks=False, trim=True):\n",
        "    if not isinstance(mid, pm.PrettyMIDI):\n",
        "        mid = pm.PrettyMIDI(str(mid))\n",
        "    notes = sum([i.notes for i in mid.instruments if not i.is_drum], start=[])\n",
        "    if trim:\n",
        "        min_start = min(n.start for n in notes)\n",
        "        for n in notes:\n",
        "            n.start -= min_start\n",
        "            n.end -= min_start\n",
        "    cropmax = np.inf\n",
        "    if crop is not None:\n",
        "        cropmax = crop[1] if isinstance(crop, tuple) else crop\n",
        "    song_length = min(max(n.end for n in notes), cropmax)\n",
        "    lines = [[(n.start + truncate, n.pitch), (n.end - truncate, n.pitch)] for n in notes]\n",
        "    max_velocity = max(n.velocity for n in notes)\n",
        "    alphas = [n.velocity / max_velocity for n in notes]\n",
        "    colors = [\"b\"] * (len(notes) - extrapolated) + [\"r\"] * extrapolated\n",
        "    if beginning_marks:\n",
        "        beginning_length = song_length * 0.01\n",
        "        beg_lc = mc.LineCollection(\n",
        "            [[(x1, y1), (min(x2, x1 + beginning_length), y2)] for [(x1, y1), (x2, y2)] in lines],\n",
        "            alpha=alphas, colors=colors)\n",
        "        lc = mc.LineCollection(lines, alpha=[a * 0.5 for a in alphas], colors=colors)\n",
        "    else:\n",
        "        lc = mc.LineCollection(lines, alpha=alphas, colors=colors)\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.set_xlabel(\"Seconds\")\n",
        "    ax.set_ylabel(\"Pitch\")\n",
        "    ax.add_collection(lc)\n",
        "    if beginning_marks:\n",
        "        ax.add_collection(beg_lc)\n",
        "    ax.autoscale()\n",
        "    if crop is not None:\n",
        "        if isinstance(crop, tuple):\n",
        "            ax.set_xlim(*crop)\n",
        "        else:\n",
        "            ax.set_xlim(0, crop)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    if filename is None:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.savefig(filename)\n",
        "        plt.close()"
      ],
      "metadata": {
        "id": "eZbSDkZ1xv-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_midi(inpath, outpath, eps_scale=(2 ** 3)):\n",
        "    mid = pm.PrettyMIDI(inpath)\n",
        "    events, shifts, tempo = midi_to_instructions(mid, eps_scale=eps_scale)\n",
        "    mid = instructions_to_midi(events, shifts, tempo)\n",
        "    mid.write(outpath)"
      ],
      "metadata": {
        "id": "t53441q-xxnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "HUsXy0dax8Ji"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIr8X4-hXnm5"
      },
      "outputs": [],
      "source": [
        "def shuffle_chords(events, shifts):\n",
        "    start = 1 # Index 0 should be a BOS token\n",
        "    N = len(events)\n",
        "    while start < N - 1: # Last token should also be BOS\n",
        "        end = start\n",
        "        for end in range(start, N):\n",
        "            if events[end] == NEXT_TOKEN:\n",
        "                break\n",
        "        if end > start + 1: # Only bother if there's >1 note\n",
        "            indices = np.arange(start, end)\n",
        "            shuffled = indices.copy()\n",
        "            np.random.shuffle(shuffled)\n",
        "            events[indices] = events[shuffled]\n",
        "            shifts[indices] = shifts[shuffled]\n",
        "        start = end + 1\n",
        "\n",
        "class PickleSet(Dataset):\n",
        "    def __init__(self, file_list, augment=True, seed=None, random_chords=False, include_boundaries=False):\n",
        "        self.file_list = list(file_list)\n",
        "        self.augment = augment\n",
        "        self.rng = np.random.default_rng(seed)\n",
        "        self.random_chords = random_chords\n",
        "        self.include_boundaries = include_boundaries\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        filename = str(self.file_list[idx])\n",
        "        with open(filename, \"rb\") as infile:\n",
        "            events, shifts, _tempo = pickle.load(infile)\n",
        "            if not self.include_boundaries:\n",
        "                events = events[1:-1]\n",
        "                shifts = shifts[1:-1]\n",
        "            if self.random_chords:\n",
        "                shuffle_chords(events, shifts)\n",
        "        if self.augment:\n",
        "            punctuation = (events == NEXT_TOKEN) | (events == BOUNDARY_TOKEN)\n",
        "            min_pitch = min(events[~punctuation])\n",
        "            max_pitch = max(events[~punctuation])\n",
        "            low = max(-7, 1 - min_pitch)\n",
        "            high = min(7, N_KEYS - max_pitch)\n",
        "            semitones = self.rng.integers(low=low, high=high+1)\n",
        "            events[~punctuation] = events[~punctuation] + semitones\n",
        "        return (\n",
        "            filename,\n",
        "            torch.tensor(events, dtype=torch.long),\n",
        "            torch.tensor(shifts, dtype=torch.long))\n",
        "\n",
        "def get_midi_list():\n",
        "    return list(pathlib.Path(\"/content/drive/My Drive/midi\").glob(\"**/*.mid\"))\n",
        "\n",
        "def get_pickle_list():\n",
        "    return list(pathlib.Path(\"/content/drive/My Drive/pickle\").glob(\"*.pickle\"))\n",
        "\n",
        "def get_training_set():\n",
        "    return list(pathlib.Path(\"/content/drive/My Drive/pickle/training\").glob(\"*.pickle\"))\n",
        "\n",
        "def get_validation_set():\n",
        "    return list(pathlib.Path(\"/content/drive/My Drive/pickle/validation\").glob(\"*.pickle\"))\n",
        "\n",
        "def collate(max_length, b, seed=None):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    masks_batch = []\n",
        "    event_batch = []\n",
        "    shift_batch = []\n",
        "    chord_batch = []\n",
        "    filenames = []\n",
        "    for filename, events, shifts in b:\n",
        "        chords = chord_position(events)\n",
        "        filenames.append(filename)\n",
        "        length = len(events)\n",
        "        if (excess := length - max_length) > 0:\n",
        "            if (rng.random() < 0.1):\n",
        "                # Take from one of the ends\n",
        "                i = 0 if rng.random() < 0.5 else excess\n",
        "            else:\n",
        "                # Take a random slice\n",
        "                i = rng.integers(low=0, high=excess+1)\n",
        "            mask = torch.ones(max_length)\n",
        "            events = events[i:i+max_length]\n",
        "            shifts = shifts[i:i+max_length]\n",
        "            chords = chords[i:i+max_length]\n",
        "            length = max_length\n",
        "        if length < max_length:\n",
        "            events = F.pad(events, (0, max_length - length))\n",
        "            shifts = F.pad(shifts, (0, max_length - length))\n",
        "            chords = F.pad(chords, (0, max_length - length))\n",
        "            mask = torch.cat([torch.ones(length), torch.zeros(max_length - length)])\n",
        "        masks_batch.append(mask)\n",
        "        event_batch.append(events)\n",
        "        shift_batch.append(shifts)\n",
        "        chord_batch.append(chords)\n",
        "    return (\n",
        "        filenames,\n",
        "        torch.stack(masks_batch).to(device),\n",
        "        torch.stack(event_batch).to(device),\n",
        "        torch.stack(shift_batch).to(device),\n",
        "        torch.stack(chord_batch).to(device))\n",
        "\n",
        "def batch_cycle(dataloader):\n",
        "    while True:\n",
        "        for batch in dataloader:\n",
        "            yield batch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def refresh_dataset(convert=False):\n",
        "    print(\"Deleting old pickles\")\n",
        "    print(\"   ... from the training set ...\")\n",
        "    for path in progress(get_training_set()):\n",
        "        os.remove(path)\n",
        "    print(\"   ... from the validation set ...\")\n",
        "    for path in progress(get_validation_set()):\n",
        "        os.remove(path)\n",
        "    print(\"   ... from the parent folder ...\")\n",
        "    for path in progress(get_pickle_list()):\n",
        "        os.remove(path)\n",
        "\n",
        "    print(\"Creating new pickles ...\")\n",
        "    for path in progress(get_midi_list()):\n",
        "        base = str(path.parent / path.stem).replace(\"/\", \"_\")\n",
        "        pickle_name = base + \".pickle\"\n",
        "        filename = str(path)\n",
        "        with warnings.catch_warnings():\n",
        "            warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "            mid = pm.PrettyMIDI(filename)\n",
        "        stuff = midi_to_instructions(mid)\n",
        "        if convert:\n",
        "            try:\n",
        "                mid = instructions_to_midi(*stuff)\n",
        "                converted_name = base + \".mid\"\n",
        "                mid.write(\"/content/drive/My Drive/converted/\" + converted_name)\n",
        "            except Exception as e:\n",
        "                print(f\"Caught exception while converting file {path}: {e}\")\n",
        "                continue\n",
        "        with open(\"/content/drive/My Drive/pickle/\" + pickle_name, \"wb\") as outfile:\n",
        "            pickle.dump(stuff, outfile)\n",
        "\n",
        "    print(\"Making training and validation sets ...\")\n",
        "    for path in progress(get_pickle_list()):\n",
        "        if np.random.rand() < 0.01:\n",
        "            path.rename(path.parent / \"validation\" / path.name)\n",
        "        else:\n",
        "            path.rename(path.parent / \"training\" / path.name)\n",
        "    print(\"Done!\")"
      ],
      "metadata": {
        "id": "52orf1lPJ39I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#refresh_dataset(convert=True)"
      ],
      "metadata": {
        "id": "BN2a6JL8rN_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plots"
      ],
      "metadata": {
        "id": "ZhtvUQVDK1dW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_attention(A, filename=None, standardize=False, title=\"Attention heads\"):\n",
        "    A = A.detach()\n",
        "    if (d := A.dim()) not in [2, 3]:\n",
        "        raise ValueError(f\"Attention must have dimension 2 or 3, but got {d}\")\n",
        "    if d == 2:\n",
        "        A = A.unsqueeze(0)\n",
        "    if standardize:\n",
        "        A = A * torch.arange(1, A.shape[1] + 1).view(1, A.shape[1], 1)\n",
        "    nrow = int(np.floor(np.sqrt(A.shape[0])))\n",
        "    ncol = int(np.ceil(np.sqrt(A.shape[0])))\n",
        "    fig, axs = plt.subplots(nrow, ncol, layout=\"constrained\")\n",
        "    cmap = plt.cm.hot\n",
        "    cmap.set_bad(\"k\", 0.5)\n",
        "    for h in range(A.shape[0]):\n",
        "        try:\n",
        "            ax = axs.flat[h]\n",
        "        except AttributeError: # No method flat\n",
        "            ax = axs\n",
        "        ax.invert_yaxis()\n",
        "        a = A[h].numpy()\n",
        "        a = np.ma.masked_array(a, mask=np.triu(np.ones_like(a), 1))\n",
        "        pcm = ax.pcolormesh(a, cmap=cmap)\n",
        "        ax.set_title(f\"Head {h+1}\")\n",
        "    h += 1\n",
        "    while h < nrow * ncol:\n",
        "        axs.flat[h].set_visible(False)\n",
        "        h += 1\n",
        "    try:\n",
        "        for i, ax in enumerate(axs.flat):\n",
        "            if i % ncol != 0:\n",
        "                ax.get_yaxis().set_visible(False)\n",
        "            if i < (nrow - 1) * ncol:\n",
        "                ax.get_xaxis().set_visible(False)\n",
        "    except AttributeError: # No flat\n",
        "        fig.colorbar(pcm)\n",
        "    else:\n",
        "        fig.colorbar(pcm, ax=axs[..., -1])\n",
        "    fig.suptitle(title)\n",
        "    if filename is not None:\n",
        "        plt.savefig(filename)"
      ],
      "metadata": {
        "id": "i1AQuFiqFYCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__oMrbSoR-pu"
      },
      "source": [
        "# Modules"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parts"
      ],
      "metadata": {
        "id": "IenuUMBuyQ1T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Relative position"
      ],
      "metadata": {
        "id": "o3HrI9g9K84G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rot(x):\n",
        "    assert x.shape[-1] % 2 == 0, f\"Input must have even last dimension, got {x.shape[-1]}\"\n",
        "    return torch.stack([-x[..., 1::2], x[..., 0::2]], dim=-1).flatten(-2)"
      ],
      "metadata": {
        "id": "IdFJuu_5jXoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RotaryEncoding(nn.Module):\n",
        "    def __init__(self, **config):\n",
        "        super().__init__()\n",
        "        for hp in [\"d_qk\", \"n_heads\", \"max_context\", \"decay_base\", \"zeta_floor\"]:\n",
        "            setattr(self, hp, config[hp])\n",
        "        if (self.d_qk // self.n_heads) % 4 != 0:\n",
        "            raise ValueError(f\"`d_qk / n_heads` must be a multiple of 4, got {self.d_qk // self.n_heads}\")\n",
        "        M = (self.d_qk // self.n_heads) / (4 * np.log2(self.max_context))\n",
        "        self.theta = 2 * torch.pi * 2 ** (-torch.arange((self.d_qk // self.n_heads) // 4) / M)\n",
        "        self.zeta = torch.maximum(self.decay_base ** (self.theta / (2 * torch.pi)), torch.tensor(self.zeta_floor))\n",
        "\n",
        "    def forward(self, Q, K, m=None):\n",
        "        if m is None:\n",
        "            m = torch.arange(Q.shape[-2])\n",
        "        m = m.view(-1, 1)\n",
        "        arg = m * self.theta.view(1, -1)\n",
        "        c = torch.cos(arg); c = torch.stack([c, c], dim=-1).flatten(-2)\n",
        "        s = torch.sin(arg); s = torch.stack([s, s], dim=-1).flatten(-2)\n",
        "        Cq = torch.cat([c,  c], dim=-1).to(device)\n",
        "        Sq = torch.cat([s,  s], dim=-1).to(device)\n",
        "        Ck = torch.cat([c, -s], dim=-1).to(device)\n",
        "        Sk = torch.cat([s,  c], dim=-1).to(device)\n",
        "        T = torch.pow(self.zeta.view(1, -1), m)\n",
        "        T = torch.stack([T, T], dim=-1).flatten(-2)\n",
        "        T = torch.cat([T, T], dim=-1).to(device)\n",
        "        for _ in range(Q.dim() - 2):\n",
        "            Cq = Cq.unsqueeze(0); Sq = Sq.unsqueeze(0)\n",
        "            Ck = Ck.unsqueeze(0); Sk = Sk.unsqueeze(0)\n",
        "            T = T.unsqueeze(0)\n",
        "        Q = (Q * Cq + rot(Q) * Sq) * T\n",
        "        K = (K * Ck + rot(K) * Sk) / T\n",
        "        return (Q, K)"
      ],
      "metadata": {
        "id": "gTLiisgN-ZsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attention"
      ],
      "metadata": {
        "id": "qET1lF0hSKhu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Drophead(nn.Module):\n",
        "    def __init__(self, p, eps=DEFAULT_EPSILON):\n",
        "        super().__init__()\n",
        "        self.p = p\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, y):\n",
        "        if not self.training:\n",
        "            return y\n",
        "        *b, h = y.shape[:-2]\n",
        "        mask = torch.bernoulli(torch.full((*b, h), 1 - self.p)).to(device)\n",
        "        mask = mask.view(*b, h, 1, 1)\n",
        "        scale = h / (mask.sum(dim=-3, keepdim=True) + self.eps)\n",
        "        return y * mask * scale"
      ],
      "metadata": {
        "id": "RMAO3SwUr9zg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MusicAttention(nn.Module):\n",
        "    def __init__(self, **config):\n",
        "        super().__init__()\n",
        "        for hp in [\"d_model\", \"n_heads\", \"initial_window\", \"d_qk\", \"d_v\"]:\n",
        "            setattr(self, hp, config[hp])\n",
        "        if self.d_qk % self.n_heads != 0:\n",
        "            raise ValueError(f\"`d_qk` must be a multiple of `n_heads`, got {self.d_qk} and {self.n_heads}\")\n",
        "        if self.d_v % self.n_heads != 0:\n",
        "            raise ValueError(f\"`d_v` must be a multiple of `n_heads`, got {self.d_v} and {self.n_heads}\")\n",
        "        self.same_chord = nn.Parameter(torch.randn(self.d_qk) / np.sqrt(self.d_qk))\n",
        "        self.Q = nn.Linear(self.d_model, self.d_qk, bias=False)\n",
        "        self.K = nn.Linear(self.d_model, self.d_qk, bias=False)\n",
        "        self.V = nn.Linear(self.d_model, self.d_v , bias=False)\n",
        "        self.unify_heads = nn.Linear(self.d_v, self.d_model)\n",
        "\n",
        "    def initialize(self):\n",
        "        nn.init.zeros_(self.Q.weight.data)\n",
        "        for m in [self.K, self.V, self.unify_heads]:\n",
        "            nn.init.xavier_normal_(m.weight.data)\n",
        "        nn.init.zeros_(self.unify_heads.bias.data)\n",
        "\n",
        "    def forward(self, q, kv, events, shifts):\n",
        "        *b, t = q.shape[:-1]\n",
        "        w = self.initial_window\n",
        "        h = self.n_heads\n",
        "        ch = chord_indices(events).unsqueeze(-1)\n",
        "\n",
        "        matches = rolling(ch, w).squeeze(-1)\n",
        "        matches = (matches == matches[..., 0, :].unsqueeze(-2)).unsqueeze(-1).float()\n",
        "        Km = matches * self.same_chord.view((1,) * (matches.dim() - 1) + (-1,))\n",
        "        Km = Km.view(*Km.shape[:-1], h, -1)\n",
        "\n",
        "        Q = self.Q(q).view(*b, t, h, -1)\n",
        "        # Head-wise normalize before rolling, to avoid duplicating work.\n",
        "        K = rolling(l2_normalize(self.K(kv).view(*b, t, h, -1)).flatten(-2), w).view(*b, w, t, h, -1)\n",
        "        V = rolling(self.V(kv), w).view(*b, w, t, h, -1)\n",
        "\n",
        "        dot = torch.einsum(\"...THD,...WTHD->...WTH\", Q, K + Km)\n",
        "        dot = dot - torch.full(dot.shape[:-1], torch.inf).tril(diagonal=-1).unsqueeze(-1).to(device)\n",
        "        A = F.softmax(dot, dim=-3)\n",
        "\n",
        "        y = torch.einsum(\"...WTH,...WTHD->...THD\", A, V)\n",
        "        y = self.unify_heads(y.flatten(-2))\n",
        "        return (y, A)"
      ],
      "metadata": {
        "id": "9wo_Py5cBUZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qv27_uOOlTcc"
      },
      "outputs": [],
      "source": [
        "class RotaryAttention(nn.Module):\n",
        "    def __init__(self, **config):\n",
        "        super().__init__()\n",
        "        for hp in [\"d_model\", \"n_heads\", \"d_qk\", \"d_v\", \"drophead_p\"]:\n",
        "            setattr(self, hp, config[hp])\n",
        "        self.Q = nn.Linear(self.d_model, self.d_qk, bias=False)\n",
        "        self.K = nn.Linear(self.d_model, self.d_qk, bias=False)\n",
        "        self.V = nn.Linear(self.d_model, self.d_v , bias=False)\n",
        "        self.drophead = Drophead(self.drophead_p)\n",
        "        self.unify_heads = nn.Linear(self.d_v, self.d_model)\n",
        "        self.initialize()\n",
        "\n",
        "    def initialize(self):\n",
        "        nn.init.zeros_(self.Q.weight.data)\n",
        "        for m in [self.K, self.V, self.unify_heads]:\n",
        "            nn.init.xavier_normal_(m.weight.data)\n",
        "        nn.init.zeros_(self.unify_heads.bias.data)\n",
        "\n",
        "    def forward(self, q, kv, rot, t=None):\n",
        "        h = self.n_heads\n",
        "        Q = self.Q(q).view(*q.shape[:-1], h, -1).transpose(-3, -2).contiguous()\n",
        "        K = l2_normalize(self.K(kv).view(*kv.shape[:-1], h, -1)).transpose(-3, -2).contiguous()\n",
        "        V = self.V(kv).view(*kv.shape[:-1], h, -1).transpose(-3, -2).contiguous()\n",
        "        Q, K = rot(Q, K, t)\n",
        "        y = F.scaled_dot_product_attention(Q, K, V, is_causal=True)\n",
        "        y = self.drophead(y).transpose(-2, -3)\n",
        "        y = self.unify_heads(y.flatten(-2))\n",
        "        return (y, None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GGnfAlA0Fba"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, attention, **config):\n",
        "        super().__init__()\n",
        "        for hp in [\"d_model\", \"d_v\", \"d_ff\", \"n_heads\", \"dropout_p\"]:\n",
        "            setattr(self, hp, config[hp])\n",
        "        self.attention = attention\n",
        "        self.dropout_attention = nn.Dropout(self.dropout_p)\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(self.d_model, self.d_ff),\n",
        "            nn.Dropout(self.dropout_p),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(self.d_ff, self.d_model),\n",
        "            nn.Dropout(self.dropout_p))\n",
        "        self.alpha1 = nn.Parameter(torch.tensor(0.))\n",
        "        self.alpha2 = nn.Parameter(torch.tensor(0.))\n",
        "        self.initialize()\n",
        "\n",
        "    def initialize(self):\n",
        "        self.attention.initialize()\n",
        "        for m in [self.feedforward[0], self.feedforward[3]]:\n",
        "            # Type hints to make the checker shut up.\n",
        "            if isinstance(m.weight, torch.Tensor):\n",
        "                nn.init.xavier_normal_(m.weight.data)\n",
        "            if isinstance(m.bias, torch.Tensor):\n",
        "                nn.init.zeros_(m.bias.data)\n",
        "\n",
        "    def forward(self, q, kv, *args):\n",
        "        res, _ = self.attention(q, kv, *args)\n",
        "        res = self.dropout_attention(res)\n",
        "        x = q + self.alpha1 * res\n",
        "        res = self.feedforward(x)\n",
        "        x = x + self.alpha2 * res\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model class"
      ],
      "metadata": {
        "id": "n6evuye1yhGl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pb5ikBxoj4r6"
      },
      "outputs": [],
      "source": [
        "default_config = {\n",
        "    \"d_model\": 256,\n",
        "    \"max_chord\": 7,\n",
        "    \"initial_window\": 17,\n",
        "    \"d_qk\": 256,\n",
        "    \"d_v\": 512,\n",
        "    \"d_ff\": 512,\n",
        "    \"n_heads\": 8,\n",
        "    \"n_shared_blocks\": 6,\n",
        "    \"n_event_blocks\": 3,\n",
        "    \"n_shift_blocks\": 3,\n",
        "    \"dropout_p\": 0.1,\n",
        "    \"drophead_p\": 0.1,\n",
        "    \"decay_base\": 0.99,\n",
        "    \"zeta_floor\": 0.995,\n",
        "    \"max_context\": 2048\n",
        "}\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, **config):\n",
        "        super().__init__()\n",
        "        config = default_config | config\n",
        "\n",
        "        for hp in [\"n_shared_blocks\", \"n_event_blocks\", \"n_shift_blocks\", \"d_model\", \"max_chord\", \"d_qk\", \"n_heads\"]:\n",
        "            setattr(self, hp, config[hp])\n",
        "\n",
        "        self.event_embedding = nn.Embedding(N_EVENTS, self.d_model)\n",
        "        self.shift_embedding = nn.Embedding(N_SHIFTS, self.d_model)\n",
        "        self.chord_embedding = nn.Embedding(self.max_chord, self.d_model)\n",
        "        self.rot = RotaryEncoding(**config) # Used elsewhere\n",
        "\n",
        "        self.initial_block = TransformerBlock(MusicAttention(**config), **config)\n",
        "        self.shared_blocks = nn.ModuleList()\n",
        "        self.event_blocks = nn.ModuleList()\n",
        "        self.shift_blocks = nn.ModuleList()\n",
        "\n",
        "        for _ in range(self.n_shared_blocks):\n",
        "            self.shared_blocks.append(TransformerBlock(RotaryAttention(**config), **config))\n",
        "        for _ in range(self.n_event_blocks):\n",
        "            self.event_blocks.append(TransformerBlock(RotaryAttention(**config), **config))\n",
        "        for i in range(self.n_shift_blocks):\n",
        "            self.shift_blocks.append(TransformerBlock(RotaryAttention(**config), **config))\n",
        "\n",
        "        self.predict_event = nn.Linear(self.d_model, N_EVENTS)\n",
        "        self.predict_shift = nn.Linear(self.d_model, N_SHIFTS)\n",
        "\n",
        "    def initialize(self):\n",
        "        self.initial_block.initialize()\n",
        "        for b in self.shared_blocks:\n",
        "            b.initialize()\n",
        "        for b in self.event_blocks:\n",
        "            b.initialize()\n",
        "        for b in self.shift_blocks:\n",
        "            b.initialize()\n",
        "        for m in [self.predict_event, self.predict_shift]:\n",
        "            nn.init.xavier_normal_(m.weight.data)\n",
        "            nn.init.zeros_(m.bias.data)\n",
        "\n",
        "    def get_logits(self, events, shifts, chords):\n",
        "        chords = torch.minimum(chords, torch.tensor(self.max_chord - 1).to(device))\n",
        "        event_emb = self.event_embedding(events)\n",
        "        shift_emb = self.shift_embedding(shifts)\n",
        "        chord_emb = self.chord_embedding(chords)\n",
        "\n",
        "        # Shared blocks\n",
        "        x0 = event_emb + shift_emb + chord_emb\n",
        "        x = self.initial_block(x0, x0, events, shifts)\n",
        "        for b in self.shared_blocks:\n",
        "            x = b(x, x, self.rot)\n",
        "        x0 = x\n",
        "\n",
        "        # Event branch\n",
        "        x = x0\n",
        "        for b in self.event_blocks:\n",
        "            x = b(x, x, self.rot)\n",
        "        event_logits = self.predict_event(x)\n",
        "\n",
        "        # Shift branch\n",
        "        kv = x0\n",
        "        q = torch.cat([\n",
        "            event_emb[..., 1:, :] + chord_emb[..., 1:, :],\n",
        "            torch.zeros(*event_emb.shape[:-2], 1, event_emb.shape[-1]).to(device)], dim=-2)\n",
        "        for b in self.shift_blocks:\n",
        "            q = b(q, kv, self.rot)\n",
        "        shift_logits = self.predict_shift(q)\n",
        "\n",
        "        return (event_logits, shift_logits)\n",
        "\n",
        "    def loss(self, el, sl, events, shifts, masks):\n",
        "        d = (masks > 0).sum()\n",
        "        Le = -masks * torch.take_along_dim(el, events.unsqueeze(-1), -1).squeeze(-1) / d\n",
        "        Ls = -masks * torch.take_along_dim(sl, shifts.unsqueeze(-1), -1).squeeze(-1) / d\n",
        "        return (Le.sum(), Ls.sum())\n",
        "\n",
        "    def forward(self, events, shifts, chords, masks):\n",
        "        el, sl = self.get_logits(events, shifts, chords)\n",
        "        events, el = events[..., 1:], el[..., :-1, :]\n",
        "        shifts, sl = shifts[..., 1:], sl[..., :-1, :]\n",
        "        masks = masks[..., 1:]\n",
        "        el = F.log_softmax(el, dim=-1)\n",
        "        sl = F.log_softmax(sl, dim=-1)\n",
        "        return self.loss(el, sl, events, shifts, masks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GcO3C81SAnl"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def quadratic_sample(model, filename, t=100, first_event=50, first_shift=7, tempo=140):\n",
        "    events, shifts = torch.tensor([first_event]).to(device), torch.tensor([first_shift]).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in progress(range(t)):\n",
        "            chords = chord_position(events)\n",
        "            el, _ = model.get_logits(events, shifts, chords)\n",
        "            e = torch.distributions.Categorical(logits=el[-1]).sample().unsqueeze(0)\n",
        "            events = torch.cat([events, e])\n",
        "            shifts = torch.cat([shifts, torch.tensor([0]).to(device)]) # dummy\n",
        "\n",
        "            chords = chord_position(events)\n",
        "            _, sl = model.get_logits(events, shifts, chords)\n",
        "            s = torch.distributions.Categorical(logits=sl[-2]).sample().unsqueeze(0)\n",
        "            shifts = torch.cat([shifts[:-1], s])\n",
        "\n",
        "    mid = instructions_to_midi(events.to(\"cpu\"), shifts.to(\"cpu\"), tempo)\n",
        "    mid.write(filename)\n",
        "    return mid"
      ],
      "metadata": {
        "id": "lpIfFKlDlkZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43XT-xtEbgVs"
      },
      "outputs": [],
      "source": [
        "codename = \"small\"\n",
        "config = {\n",
        "    \"d_model\": 128,\n",
        "    \"d_qk\": 128,\n",
        "    \"d_v\": 256,\n",
        "    \"d_ff\": 256,\n",
        "    \"n_heads\": 8,\n",
        "    \"n_shared_blocks\": 3,\n",
        "    \"n_event_blocks\": 2,\n",
        "    \"n_shift_blocks\": 2,\n",
        "    \"max_context\": 1024\n",
        "}\n",
        "\n",
        "load_path = None #\"/content/drive/My Drive/model/small_2023-10-28_30000.pt\"\n",
        "\n",
        "if load_path is None:\n",
        "    model = Model(**config).to(device)\n",
        "    model.initialize()\n",
        "    opt = optim.Adam(model.parameters(), lr=1e-3, betas=(0.9, 0.98), eps=1e-9)\n",
        "    iteration = 0\n",
        "    event_loss_history = []\n",
        "    shift_loss_history = []\n",
        "    loss_history = []\n",
        "    validation_loss_history = []\n",
        "else:\n",
        "    saved_state = torch.load(load_path)\n",
        "    config = saved_state.get(\"config\", dict())\n",
        "    model = Model(**config).to(device)\n",
        "    model.load_state_dict(saved_state[\"model_state_dict\"])\n",
        "    opt = optim.Adam(model.parameters(), lr=1e-3, betas=(0.9, 0.98), eps=1e-9)\n",
        "    opt.load_state_dict(saved_state[\"optimizer_state_dict\"])\n",
        "    iteration = saved_state[\"iteration\"]\n",
        "    event_loss_history = saved_state[\"event_loss_history\"]\n",
        "    shift_loss_history = saved_state[\"shift_loss_history\"]\n",
        "    loss_history = saved_state[\"loss_history\"]\n",
        "    validation_loss_history = saved_state[\"validation_loss_history\"]\n",
        "\n",
        "dataset = PickleSet(get_training_set())\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=partial(collate, CONTEXT_WINDOW), drop_last=True)\n",
        "batches = batch_cycle(dataloader)\n",
        "\n",
        "model.train()\n",
        "batches = batch_cycle(dataloader)\n",
        "\n",
        "update_freq = 100\n",
        "sample_freq = 1_000\n",
        "save_freq = 5_000\n",
        "\n",
        "for i in progress(range(iteration, N_TRAINING_STEPS), update_freq):\n",
        "    _names, mask, events, shifts, chords = next(batches)\n",
        "    opt.zero_grad()\n",
        "    event_loss, shift_loss = model(events, shifts, chords, mask)\n",
        "    loss = event_loss + shift_loss\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "\n",
        "    loss_history.append(loss.item())\n",
        "    event_loss_history.append(event_loss.item())\n",
        "    shift_loss_history.append(shift_loss.item())\n",
        "\n",
        "    if (i + 1) % update_freq == 0:\n",
        "        print(f\"{i+1} iterations\")\n",
        "\n",
        "        med_loss = np.median(loss_history[-update_freq:])\n",
        "        med_event_loss = np.median(event_loss_history[-update_freq:])\n",
        "        med_shift_loss = np.median(shift_loss_history[-update_freq:])\n",
        "        print(f\"loss: {med_loss:.3f} ~ {med_event_loss:.3f} + {med_shift_loss:.3f}\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            dataset = PickleSet(get_validation_set())\n",
        "            validation = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=partial(collate, CONTEXT_WINDOW), drop_last=True)\n",
        "            v = []\n",
        "            for _names, mask, events, shifts, chords in validation:\n",
        "                event_loss, shift_loss = model(events, shifts, chords, mask)\n",
        "                v.append((event_loss + shift_loss).item())\n",
        "            med_v = np.median(v)\n",
        "            print(f\"validation: {med_v:.3f}\")\n",
        "            validation_loss_history.append(med_v)\n",
        "\n",
        "        print()\n",
        "\n",
        "    if (i + 1) % sample_freq == 0:\n",
        "        with torch.no_grad():\n",
        "            filename = f\"/content/drive/My Drive/Colab output/{codename}_{dt.date.today()}_{i+1}.mid\"\n",
        "            quadratic_sample(model, filename)\n",
        "\n",
        "    if (i + 1) % save_freq == 0:\n",
        "        save_path = f\"/content/drive/My Drive/model/{codename}_{dt.date.today()}_{i+1}.pt\"\n",
        "        torch.save(\n",
        "            {\n",
        "                \"config\": config,\n",
        "                \"iteration\": i+1,\n",
        "                \"model_state_dict\": model.state_dict(),\n",
        "                \"optimizer_state_dict\": opt.state_dict(),\n",
        "                \"event_loss_history\": event_loss_history,\n",
        "                \"shift_loss_history\": shift_loss_history,\n",
        "                \"loss_history\": loss_history,\n",
        "                \"validation_loss_history\": validation_loss_history},\n",
        "            save_path)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "pThSg2aGwDj0",
        "Xm4cNvCf2DHp",
        "3e75erekQP8v",
        "Q86FPO1rw9C0",
        "cwjvDZSbx4Mc",
        "nzg9UYWcx2i5",
        "E7u_fPJix0A3",
        "ZhtvUQVDK1dW",
        "IenuUMBuyQ1T",
        "n6evuye1yhGl"
      ],
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP4Qvbx5czR2n07kR75mSgb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}